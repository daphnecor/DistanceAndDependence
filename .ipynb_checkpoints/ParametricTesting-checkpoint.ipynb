{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric testing - least squares regression\n",
    "\n",
    "- Run all analyses (including preprocessing)\n",
    "- Save each step in dictionary: `main_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Daphne/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "''' Dependencies '''\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm as pbar\n",
    "from scipy.io import savemat, loadmat\n",
    "\n",
    "# my scripts\n",
    "from pyaldata import * \n",
    "import preprocess\n",
    "\n",
    "import TME\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "importlib.reload(TME)\n",
    "importlib.reload(preprocess)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Load data and parameterize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Parameters '''\n",
    "OTHER_ARRAY_D = 50 # Distance value to indicate other array\n",
    "\n",
    "TYPE_ANALYSIS = 'pooled' # alternative: 'm1', 'pmd' #TODO\n",
    "\n",
    "SESSIONS = ['Chewie_CO_VR_2016-09-09', 'Chewie_CO_VR_2016-09-12', 'Chewie_CO_VR_2016-09-14', 'Chewie_CO_VR_2016-10-06', \n",
    "            'Chewie_CO_FF_2016-09-15', 'Chewie_CO_FF_2016-09-21', 'Chewie_CO_FF_2016-10-05', 'Chewie_CO_FF_2016-10-07',\n",
    "            'Mihili_CO_VR_2014-03-04', 'Mihili_CO_VR_2014-03-06', 'Mihili_CO_FF_2014-02-03', 'Mihili_CO_FF_2014-02-17', \n",
    "            'Mihili_CO_FF_2014-02-18', 'Mihili_CO_FF_2014-03-07', 'Mihili_CO_VR_2014-03-03']\n",
    "\n",
    "THRESHOLDS_VARE = np.round(np.arange(0.2, 0.95, 0.025), 3)\n",
    "INTERVALS = [(0, 2), (0, 4)] # Fixed within intervals\n",
    "dim_range = [5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Experimental sessions and electrode maps '''\n",
    "m1_emap  = localize_elecs(read_cmp(file_path='/Users/Daphne/Data/Chewie Left M1 SN 6250-001474.cmp'),  elecs=range(1,97))\n",
    "pmd_emap = localize_elecs(read_cmp(file_path='/Users/Daphne/Data/Chewie Left PMd SN 6251-001469.cmp'), elecs=range(1,97))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Analyse the real data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:30<00:00,  6.02s/it]\n"
     ]
    }
   ],
   "source": [
    "''' Perform preprocessing and store '''\n",
    "\n",
    "main_dict = {} # Initialize dictionary for empirical data\n",
    "\n",
    "for s in pbar(range(len(SESSIONS))):\n",
    "    main_dict[f'{SESSIONS[s][-10:]}'] = {\n",
    "        'df' : preprocess.preprocess_data(SESSIONS[s], '/Users/Daphne/Data/'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.10it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Trial-concatenate and perform dim reduction all sessions '''\n",
    "\n",
    "for s in pbar(main_dict.keys()):\n",
    "    \n",
    "    # Select trial data for session by idx\n",
    "    td = main_dict[s]['df']\n",
    "    \n",
    "    if TYPE_ANALYSIS == 'pooled':\n",
    "        X = np.concatenate(td['both_rates'].values, axis=0) \n",
    "        N = td.both_rates[0].shape[1]\n",
    "\n",
    "    model = PCA(n_components=N)\n",
    "    model.fit(X)\n",
    "    main_dict[s]['model'] = model\n",
    "    main_dict[s]['pcs'] = model.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Prepare dictionaries to store each step for level of var exp '''\n",
    "\n",
    "# for s in main_dict.keys():\n",
    "#     main_dict[s]['vare'] = {}\n",
    "#     for th in THRESHOLDS_VARE:\n",
    "#         main_dict[s]['vare'][f'{th}'] = { 'distances_df': {} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Prepare dictionaries to store each step for level of var exp '''\n",
    "\n",
    "for s in main_dict.keys():\n",
    "    main_dict[s]['dim'] = {}\n",
    "    for d in dim_range:\n",
    "        main_dict[s]['dim'][f'{d}'] = { 'distances_df': {} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.28s/it]\n"
     ]
    }
   ],
   "source": [
    "''' Compute correlations and physical distances '''\n",
    "\n",
    "for s in pbar(main_dict.keys()):\n",
    "    \n",
    "    # Get trial data\n",
    "    td = main_dict[s]['df']\n",
    "    #components_range = [np.argmax(main_dict[s]['model'].explained_variance_ratio_.cumsum() > THRESHOLDS_VARE[i]) for i in range(len(THRESHOLDS_VARE))]\n",
    "    \n",
    "    for i, r in enumerate(dim_range):\n",
    "\n",
    "        if r < 2: r += 1 # Can't compute correlation between two values\n",
    "\n",
    "        L = main_dict[s]['pcs'][:, :r] # Get the first r PCs\n",
    "\n",
    "        # Get correlations and physical distances\n",
    "        C, PD, A, _  = compute_stat_and_phys_distances(L, td['M1_unit_guide'][0], td['PMd_unit_guide'][0], m1_emap, pmd_emap)\n",
    "        \n",
    "        # Convert to dataframe\n",
    "        df = pd.DataFrame(data={'correlation': C, 'distance': PD, 'on array': A})\n",
    "        df['category'] = df['distance'].apply(lambda d: 'same electrode' if d == 0 else ('same array' if d < OTHER_ARRAY_D else ('other array')))\n",
    "        df['within distance'] = pd.cut(df['distance'], bins=[-0.1, 0.001, 2.01, 4.01, OTHER_ARRAY_D], labels=['0', '(0, 2]','(2, 4]', '(4, inf)'])\n",
    "        df['Type'] = 'Actual'\n",
    "        \n",
    "        # Store dataframe in main dictionary\n",
    "        #main_dict[s]['vare'][f'{THRESHOLDS_VARE[i]}']['distances_df'] = df\n",
    "        \n",
    "        # Based on manifold dim\n",
    "        main_dict[s]['dim'][f'{dim_range[i]}']['distances_df'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['5', '10', '15', '20'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dict[s]['dim'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:10<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for s in pbar(main_dict.keys()):\n",
    "    \n",
    "    for v in main_dict[s]['dim'].keys(): \n",
    "        \n",
    "        # Empirical and surrogate data\n",
    "        variants = {\n",
    "          'Actual' : main_dict[s]['dim'][f'{v}']['distances_df'],\n",
    "        }\n",
    "        # Dummy functions\n",
    "        int_dum = lambda df, lb, ub: df['distance'].apply(lambda x: 1 if lb < x <= ub else 0)\n",
    "        on_arr = lambda df, arr: df['on array'].apply(lambda x: 1 if x == arr else 0)\n",
    "        same_ele = lambda df: df['distance'].apply(lambda x: 1 if x == 0 else 0)\n",
    "        same_arr = lambda df: df['distance'].apply(lambda x: 1 if 0 < x < OTHER_ARRAY_D else 0)\n",
    "\n",
    "        # Analyses methods\n",
    "        analyses = {\n",
    "          'single_cat' : {\n",
    "            'fixed cols' : {\n",
    "              'OA Constant' : lambda df: [1] * len(df),\n",
    "              'SE (d = 0)' : same_ele,\n",
    "              'SA (d exists)' : same_arr,\n",
    "            },\n",
    "            'variable cols' : {}\n",
    "          },\n",
    "          'within' : {\n",
    "            'fixed cols' : {\n",
    "              'M1 Constant' : lambda df: on_arr(df, 'M1'),\n",
    "              'OA Constant' : lambda df: on_arr(df, 'OA'),\n",
    "              'PMd Constant' : lambda df: on_arr(df, 'PMd'),\n",
    "              'SE (d = 0)' : same_ele\n",
    "            },\n",
    "            'variable cols' : {\n",
    "              'd in ' : lambda df, lb, ub: int_dum(df, lb, ub),\n",
    "            },\n",
    "          },\n",
    "          'within_separate' : {\n",
    "            'fixed cols' : {\n",
    "              'M1 Constant' : lambda df: on_arr(df, 'M1'),\n",
    "              'OA Constant' : lambda df: on_arr(df, 'OA'),\n",
    "              'PMd Constant' : lambda df: on_arr(df, 'PMd'),\n",
    "              'M1 SE (d = 0)' : lambda df: on_arr(df, 'M1') * same_ele(df),\n",
    "              'PMd SE (d = 0)' : lambda df: on_arr(df, 'PMd') * same_ele(df),\n",
    "            },\n",
    "            'variable cols' : {\n",
    "              'M1 d in ' : lambda df, lb, ub: int_dum(df, lb, ub) * on_arr(df, 'M1'),\n",
    "              'PMd d in ' : lambda df, lb, ub: int_dum(df, lb, ub) * on_arr(df, 'PMd'),\n",
    "            }\n",
    "          },\n",
    "        }\n",
    "        \n",
    "        for study, df in variants.items():\n",
    "            \n",
    "            for analysis, cols_dict in analyses.items():\n",
    "                df_X = pd.DataFrame()\n",
    "                for col_name, col_func in cols_dict['fixed cols'].items():\n",
    "                    df_X[col_name] = col_func(df)\n",
    "                for (lb, ub) in INTERVALS:\n",
    "                    for col_name, col_func in cols_dict['variable cols'].items():\n",
    "                        df_X[col_name + f'({lb:.1f}, {ub:.1f}]'] = col_func(df, lb, ub)\n",
    "                df_X = df_X.reindex(sorted(df_X.columns), axis=1)\n",
    "                res = sm.OLS(df.correlation, df_X, hasconst=True).fit()\n",
    "                title = f'{study}_{analysis}'\n",
    "                \n",
    "                #if study == 'Actual': main_dict[s]['vare'][f'{v}'][title] = res\n",
    "                \n",
    "                if study == 'Actual': main_dict[s]['dim'][f'{v}'][title] = res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('main_dict_dims.npy', main_dict) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Analyse surrogate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load unit guides '''\n",
    "M1_UG = np.load('M1_UG.npy')\n",
    "PMD_UG = np.load('PMD_UG.npy')\n",
    "\n",
    "S = scipy.io.loadmat('/Users/Daphne/Data/SurrTensor.mat')['S'] # Get surrogates\n",
    "# Select subset \n",
    "S = S[:, :, 20:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 218, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Initialize dictionary '''\n",
    "\n",
    "surr_dict = {}\n",
    "for s in range(S.shape[2]): surr_dict[f'{s+20}'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:05<00:00,  5.01it/s]\n"
     ]
    }
   ],
   "source": [
    "N = S.shape[1]\n",
    "\n",
    "for surr in pbar(surr_dict.keys()):\n",
    "    \n",
    "    X_surr = S[:, :, int(surr)-20]\n",
    "    \n",
    "    model_surr = PCA(n_components=N)\n",
    "    model_surr.fit(X_surr)\n",
    "    surr_dict[surr]['model'] = model_surr\n",
    "    surr_dict[surr]['pcs'] = model_surr.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Prepare dictionaries to store each step for level of var exp '''\n",
    "\n",
    "for s in surr_dict.keys():\n",
    "    surr_dict[s]['vare'] = {}\n",
    "    for th in THRESHOLDS_VARE:\n",
    "        surr_dict[s]['vare'][f'{th}'] = { 'distances_df': {} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [16:16<00:00, 32.54s/it]\n"
     ]
    }
   ],
   "source": [
    "for s in pbar(surr_dict.keys()):\n",
    "    \n",
    "    components_range = [np.argmax(surr_dict[s]['model'].explained_variance_ratio_.cumsum() > THRESHOLDS_VARE[i]) for i in range(len(THRESHOLDS_VARE))]\n",
    "\n",
    "    for i, r in enumerate(components_range):\n",
    "\n",
    "        if r == 0: r += 2 # Can't compute correlation between two values\n",
    "        elif r == 1: r += 1 \n",
    "            \n",
    "        L_surr = surr_dict[s]['pcs'][:, :r] # Get the first r PCs\n",
    "\n",
    "        # Get correlations and physical distances\n",
    "        C, PD, A, _ = compute_stat_and_phys_distances(L_surr, M1_UG, PMD_UG, m1_emap, pmd_emap)\n",
    "        \n",
    "        # Convert to dataframe\n",
    "        df = pd.DataFrame(data={'correlation': C, 'distance': PD, 'on array': A})\n",
    "        df['category'] = df['distance'].apply(lambda d: 'same electrode' if d == 0 else ('same array' if d < OTHER_ARRAY_D else ('other array')))\n",
    "        df['within distance'] = pd.cut(df['distance'], bins=[-0.1, 0.001, 2.01, 4.01, OTHER_ARRAY_D], labels=['0', '(0, 2]','(2, 4]', '(4, inf)'])\n",
    "        df['Type'] = 'Surrogate'\n",
    "        \n",
    "        # Store dataframe in surrogate dictionary\n",
    "        surr_dict[s]['vare'][f'{THRESHOLDS_VARE[i]}']['distances_df'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:05<00:00,  6.18s/it]\n"
     ]
    }
   ],
   "source": [
    "for s in pbar(surr_dict.keys()):\n",
    "    \n",
    "    for v in surr_dict[s]['vare'].keys(): \n",
    "        \n",
    "        # Empirical and surrogate data\n",
    "        variants = {\n",
    "          'Surr' : surr_dict[s]['vare'][f'{v}']['distances_df'],\n",
    "        }\n",
    "        # Dummy functions\n",
    "        int_dum = lambda df, lb, ub: df['distance'].apply(lambda x: 1 if lb < x <= ub else 0)\n",
    "        on_arr = lambda df, arr: df['on array'].apply(lambda x: 1 if x == arr else 0)\n",
    "        same_ele = lambda df: df['distance'].apply(lambda x: 1 if x == 0 else 0)\n",
    "        same_arr = lambda df: df['distance'].apply(lambda x: 1 if 0 < x < OTHER_ARRAY_D else 0)\n",
    "\n",
    "        # Analyses methods\n",
    "        analyses = {\n",
    "          'single_cat' : {\n",
    "            'fixed cols' : {\n",
    "              'OA Constant' : lambda df: [1] * len(df),\n",
    "              'SE (d = 0)' : same_ele,\n",
    "              'SA (d exists)' : same_arr,\n",
    "            },\n",
    "            'variable cols' : {}\n",
    "          },\n",
    "          'within' : {\n",
    "            'fixed cols' : {\n",
    "              'M1 Constant' : lambda df: on_arr(df, 'M1'),\n",
    "              'OA Constant' : lambda df: on_arr(df, 'OA'),\n",
    "              'PMd Constant' : lambda df: on_arr(df, 'PMd'),\n",
    "              'SE (d = 0)' : same_ele\n",
    "            },\n",
    "            'variable cols' : {\n",
    "              'd in ' : lambda df, lb, ub: int_dum(df, lb, ub),\n",
    "            },\n",
    "          },\n",
    "          'within_separate' : {\n",
    "            'fixed cols' : {\n",
    "              'M1 Constant' : lambda df: on_arr(df, 'M1'),\n",
    "              'OA Constant' : lambda df: on_arr(df, 'OA'),\n",
    "              'PMd Constant' : lambda df: on_arr(df, 'PMd'),\n",
    "              'M1 SE (d = 0)' : lambda df: on_arr(df, 'M1') * same_ele(df),\n",
    "              'PMd SE (d = 0)' : lambda df: on_arr(df, 'PMd') * same_ele(df),\n",
    "            },\n",
    "            'variable cols' : {\n",
    "              'M1 d in ' : lambda df, lb, ub: int_dum(df, lb, ub) * on_arr(df, 'M1'),\n",
    "              'PMd d in ' : lambda df, lb, ub: int_dum(df, lb, ub) * on_arr(df, 'PMd'),\n",
    "            }\n",
    "          },\n",
    "        }\n",
    "        \n",
    "        for study, df in variants.items():\n",
    "            \n",
    "            for analysis, cols_dict in analyses.items():\n",
    "                df_X = pd.DataFrame()\n",
    "                for col_name, col_func in cols_dict['fixed cols'].items():\n",
    "                    df_X[col_name] = col_func(df)\n",
    "                for (lb, ub) in INTERVALS:\n",
    "                    for col_name, col_func in cols_dict['variable cols'].items():\n",
    "                        df_X[col_name + f'({lb:.1f}, {ub:.1f}]'] = col_func(df, lb, ub)\n",
    "                df_X = df_X.reindex(sorted(df_X.columns), axis=1)\n",
    "                res = sm.OLS(df.correlation, df_X, hasconst=True).fit()\n",
    "                title = f'{study}_{analysis}'\n",
    "                \n",
    "                surr_dict[s]['vare'][f'{v}'][title] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('surr_dict_30.npy', surr_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_dict[s]['vare']['0.2']['Actual_single_cat'].params.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeffs = []\n",
    "\n",
    "# for i, v in enumerate(main_dict[s]['vare'].keys()):\n",
    "    \n",
    "#     coeffs.append(main_dict[s]['vare'][f'{v}']['Actual_single_cat'].params.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Select real data to generate surrogates '''\n",
    "# # X = np.concatenate(main_dict['2016-09-09']['df']['both_rates'].values, axis=0) \n",
    "# # X = X[:5000, :]\n",
    "\n",
    "# # savemat('X_concat_full.mat', {'X_CF':X}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "uni"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
