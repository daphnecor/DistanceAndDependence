{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Dependencies '''\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm as pbar\n",
    "\n",
    "# my scripts\n",
    "from pyaldata import * \n",
    "import preprocess\n",
    "\n",
    "import TME\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "importlib.reload(TME)\n",
    "importlib.reload(preprocess)\n",
    "from utils import *\n",
    "\n",
    "# Plotting\n",
    "# from matplotlib.offsetbox import AnchoredText\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and parameterize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Parameters '''\n",
    "OTHER_ARRAY_D = 50 # Distance value to indicate other array\n",
    "\n",
    "TYPE_ANALYSIS = 'pooled' # alternative: 'm1', 'pmd' #TODO\n",
    "\n",
    "SESSIONS = ['Chewie_CO_VR_2016-09-09', 'Chewie_CO_VR_2016-09-12', 'Chewie_CO_VR_2016-09-14', 'Chewie_CO_VR_2016-10-06', \n",
    "            'Chewie_CO_FF_2016-09-15', 'Chewie_CO_FF_2016-09-21', 'Chewie_CO_FF_2016-10-05', 'Chewie_CO_FF_2016-10-07',\n",
    "            'Mihili_CO_VR_2014-03-04', 'Mihili_CO_VR_2014-03-06', 'Mihili_CO_FF_2014-02-03', 'Mihili_CO_FF_2014-02-17', \n",
    "            'Mihili_CO_FF_2014-02-18', 'Mihili_CO_FF_2014-03-07', 'Mihili_CO_VR_2014-03-03']\n",
    "\n",
    "THRESHOLDS_VARE = np.round(np.arange(0.2, 0.95, 0.025), 3)\n",
    "INTERVALS = [(0, 2), (0, 4)] # Fixed within intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Experimental sessions and electrode maps '''\n",
    "m1_emap  = localize_elecs(read_cmp(file_path='/Users/Daphne/Data/Chewie Left M1 SN 6250-001474.cmp'),  elecs=range(1,97))\n",
    "pmd_emap = localize_elecs(read_cmp(file_path='/Users/Daphne/Data/Chewie Left PMd SN 6251-001469.cmp'), elecs=range(1,97))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "Surr = scipy.io.loadmat('/Users/Daphne/Data/S.mat')['S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 218, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Surr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:06<01:26,  6.17s/it]"
     ]
    }
   ],
   "source": [
    "''' Perform preprocessing and store '''\n",
    "\n",
    "main_dict = {} # Initialize dictionary for empirical data\n",
    "\n",
    "for s in pbar(range(len(SESSIONS))):\n",
    "    main_dict[f'{SESSIONS[s][-10:]}'] = {\n",
    "        'df' : preprocess.preprocess_data(SESSIONS[s], '/Users/Daphne/Data/'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2016-09-09', '2016-09-12', '2016-09-14', '2016-10-06', '2016-09-15', '2016-09-21', '2016-10-05', '2016-10-07', '2014-03-04', '2014-03-06', '2014-02-03', '2014-02-17', '2014-02-18', '2014-03-07', '2014-03-03'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dict[s]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'savemat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a0a0e6036845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2016-09-09'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'df'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'both_rates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msavemat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_concat_.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurr_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'savemat' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.io import savemat, loadmat\n",
    "\n",
    "X = np.concatenate(main_dict['2016-09-09']['df']['both_rates'].values, axis=0) \n",
    "\n",
    "savemat('X_concat_2016-09-09.mat', surr_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:02<00:00,  6.77it/s]\n"
     ]
    }
   ],
   "source": [
    "surr_dict = {} # Initialize dictionary for surrogate data\n",
    "i = 0\n",
    "\n",
    "for s in pbar(main_dict.keys()):\n",
    "    \n",
    "    # Select trial data for session by idx\n",
    "    td = main_dict[s]['df']\n",
    "    X = np.concatenate(td['both_rates'].values, axis=0) \n",
    "    \n",
    "    surr_dict[f'{i}'] = X\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat, loadmat\n",
    "\n",
    "savemat('surr_dict.mat', surr_dict) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Trial-concatenate and perform dim reduction all sessions '''\n",
    "\n",
    "for s in pbar(main_dict.keys()):\n",
    "    \n",
    "    # Select trial data for session by idx\n",
    "    td = main_dict[s]['df']\n",
    "    \n",
    "    if TYPE_ANALYSIS == 'pooled':\n",
    "        X = np.concatenate(td['both_rates'].values, axis=0) \n",
    "        N = td.both_rates[0].shape[1]\n",
    "        \n",
    "#     elif TYPE_ANALYSIS == 'm1':   \n",
    "#         X = np.concatenate(td['M1_rates'].values, axis=0)\n",
    "#         N = td.M1_rates[0].shape[1]\n",
    "\n",
    "#     elif TYPE_ANALYSIS == 'pmd':  \n",
    "#         X = np.concatenate(td['PMd_rates'].values, axis=0)\n",
    "#         N = td.PMd_rates[0].shape[1]\n",
    "        \n",
    "    # Generate Surrogates\n",
    "    X_surr = TME.TensorMaximumEntropy(X)\n",
    "    \n",
    "    # True data\n",
    "    model = PCA(n_components=N)\n",
    "    model.fit(X)\n",
    "    main_dict[s]['model'] = model\n",
    "    main_dict[s]['pcs'] = model.components_.T\n",
    "   \n",
    "    # Surrogate\n",
    "    model_surr = PCA(n_components=N)\n",
    "    model_surr.fit(X_surr)\n",
    "    surr_dict[s]['model'] = model_surr\n",
    "    surr_dict[s]['pcs'] = model_surr.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('surr_dict.npy', surr_dict) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataframes with correlations and spatial distances for real data, surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in main_dict.keys():\n",
    "    main_dict[s]['vare'] = {}\n",
    "    for th in THRESHOLDS_VARE:\n",
    "        main_dict[s]['vare'][f'{th}'] = { 'distances_df': {} }\n",
    "        \n",
    "for s in surr_dict.keys():\n",
    "    surr_dict[s]['vare'] = {}\n",
    "    for th in THRESHOLDS_VARE:\n",
    "        surr_dict[s]['vare'][f'{th}'] = { 'distances_df': {} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in pbar(main_dict.keys()):\n",
    "    \n",
    "    # Get trial data\n",
    "    td = main_dict[s]['df']\n",
    "    components_range = [np.argmax(main_dict[s]['model'].explained_variance_ratio_.cumsum() > THRESHOLDS_VARE[i]) for i in range(len(THRESHOLDS_VARE))]\n",
    "    \n",
    "    for i, r in enumerate(components_range):\n",
    "\n",
    "        if r < 2: r += 1 # Can't compute correlation between two values\n",
    "\n",
    "        L = main_dict[s]['pcs'][:, :r] # Get the first r PCs\n",
    "\n",
    "        # Get correlations and physical distances\n",
    "        C, PD, A = compute_stat_and_phys_distances(L, td['M1_unit_guide'][0], td['PMd_unit_guide'][0], m1_emap, pmd_emap)\n",
    "        \n",
    "        # Convert to dataframe\n",
    "        df = pd.DataFrame(data={'correlation': C, 'distance': PD, 'on array': A})\n",
    "        df['category'] = df['distance'].apply(lambda d: 'same electrode' if d == 0 else ('same array' if d < OTHER_ARRAY_D else ('other array')))\n",
    "        df['within distance'] = pd.cut(df['distance'], bins=[-0.1, 0.001, 2.01, 4.01, OTHER_ARRAY_D], labels=['0', '(0, 2]','(2, 4]', '(4, inf)'])\n",
    "        df['Type'] = 'Actual'\n",
    "        \n",
    "        # Store dataframe in main dictionary\n",
    "        main_dict[s]['vare'][f'{THRESHOLDS_VARE[i]}']['distances_df'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in pbar(surr_dict.keys()):\n",
    "    \n",
    "    # Get trial data\n",
    "    td = main_dict[s]['df']\n",
    "    components_range = [np.argmax(surr_dict[s]['model'].explained_variance_ratio_.cumsum() > THRESHOLDS_VARE[i]) for i in range(len(THRESHOLDS_VARE))]\n",
    "\n",
    "    for i, r in enumerate(components_range):\n",
    "\n",
    "        if r < 2: r += 1 # Can't compute correlation between two values\n",
    "\n",
    "        L_surr = surr_dict[s]['pcs'][:, :r] # Get the first r PCs\n",
    "\n",
    "        # Get correlations and physical distances\n",
    "        C, PD, A = compute_stat_and_phys_distances(L_surr, td['M1_unit_guide'][0], td['PMd_unit_guide'][0], m1_emap, pmd_emap)\n",
    "        \n",
    "        # Convert to dataframe\n",
    "        df = pd.DataFrame(data={'correlation': C, 'distance': PD, 'on array': A})\n",
    "        df['category'] = df['distance'].apply(lambda d: 'same electrode' if d == 0 else ('same array' if d < OTHER_ARRAY_D else ('other array')))\n",
    "        df['within distance'] = pd.cut(df['distance'], bins=[-0.1, 0.001, 2.01, 4.01, OTHER_ARRAY_D], labels=['0', '(0, 2]','(2, 4]', '(4, inf)'])\n",
    "        df['Type'] = 'Surrogate'\n",
    "        \n",
    "        # Store dataframe in surrogate dictionary\n",
    "        surr_dict[s]['vare'][f'{THRESHOLDS_VARE[i]}']['distances_df'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in pbar(main_dict.keys()):\n",
    "    \n",
    "    for v in main_dict[s]['vare'].keys(): \n",
    "        \n",
    "        # Empirical and surrogate data\n",
    "        variants = {\n",
    "          'Actual' : main_dict[s]['vare'][f'{v}']['distances_df'],\n",
    "          'Surrogate' : surr_dict[s]['vare'][f'{v}']['distances_df'],\n",
    "        }\n",
    "        # Dummy functions\n",
    "        int_dum = lambda df, lb, ub: df['distance'].apply(lambda x: 1 if lb < x <= ub else 0)\n",
    "        on_arr = lambda df, arr: df['on array'].apply(lambda x: 1 if x == arr else 0)\n",
    "        same_ele = lambda df: df['distance'].apply(lambda x: 1 if x == 0 else 0)\n",
    "        same_arr = lambda df: df['distance'].apply(lambda x: 1 if 0 < x < OTHER_ARRAY_D else 0)\n",
    "\n",
    "        # Analyses methods\n",
    "        analyses = {\n",
    "          'single_cat' : {\n",
    "            'fixed cols' : {\n",
    "              'OA Constant' : lambda df: [1] * len(df),\n",
    "              'SE (d = 0)' : same_ele,\n",
    "              'SA (d exists)' : same_arr,\n",
    "            },\n",
    "            'variable cols' : {}\n",
    "          },\n",
    "          'within' : {\n",
    "            'fixed cols' : {\n",
    "              'M1 Constant' : lambda df: on_arr(df, 'M1'),\n",
    "              'OA Constant' : lambda df: on_arr(df, 'OA'),\n",
    "              'PMd Constant' : lambda df: on_arr(df, 'PMd'),\n",
    "              'SE (d = 0)' : same_ele\n",
    "            },\n",
    "            'variable cols' : {\n",
    "              'd in ' : lambda df, lb, ub: int_dum(df, lb, ub),\n",
    "            },\n",
    "          },\n",
    "          'within_separate' : {\n",
    "            'fixed cols' : {\n",
    "              'M1 Constant' : lambda df: on_arr(df, 'M1'),\n",
    "              'OA Constant' : lambda df: on_arr(df, 'OA'),\n",
    "              'PMd Constant' : lambda df: on_arr(df, 'PMd'),\n",
    "              'M1 SE (d = 0)' : lambda df: on_arr(df, 'M1') * same_ele(df),\n",
    "              'PMd SE (d = 0)' : lambda df: on_arr(df, 'PMd') * same_ele(df),\n",
    "            },\n",
    "            'variable cols' : {\n",
    "              'M1 d in ' : lambda df, lb, ub: int_dum(df, lb, ub) * on_arr(df, 'M1'),\n",
    "              'PMd d in ' : lambda df, lb, ub: int_dum(df, lb, ub) * on_arr(df, 'PMd'),\n",
    "            }\n",
    "          },\n",
    "        }\n",
    "        \n",
    "        for study, df in variants.items():\n",
    "            \n",
    "            for analysis, cols_dict in analyses.items():\n",
    "                df_X = pd.DataFrame()\n",
    "                for col_name, col_func in cols_dict['fixed cols'].items():\n",
    "                    df_X[col_name] = col_func(df)\n",
    "                for (lb, ub) in INTERVALS:\n",
    "                    for col_name, col_func in cols_dict['variable cols'].items():\n",
    "                        df_X[col_name + f'({lb:.1f}, {ub:.1f}]'] = col_func(df, lb, ub)\n",
    "                df_X = df_X.reindex(sorted(df_X.columns), axis=1)\n",
    "                res = sm.OLS(df.correlation, df_X, hasconst=True).fit()\n",
    "                title = f'{study}_{analysis}'\n",
    "                \n",
    "                if study == 'Actual': main_dict[s]['vare'][f'{v}'][title] = res\n",
    "                elif study == 'Surrogate': surr_dict[s]['vare'][f'{v}'][title] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('surr_dict.npy', surr_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_dict[s]['vare']['0.2']['Actual_single_cat'].params.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeffs = []\n",
    "\n",
    "# for i, v in enumerate(main_dict[s]['vare'].keys()):\n",
    "    \n",
    "#     coeffs.append(main_dict[s]['vare'][f'{v}']['Actual_single_cat'].params.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "uni"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
