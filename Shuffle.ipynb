{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Daphne/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "''' Dependencies '''\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm as pbar\n",
    "\n",
    "# my scripts\n",
    "from pyaldata import * \n",
    "import preprocess\n",
    "from utils import *\n",
    "\n",
    "# Plotting\n",
    "from IPython.display import display, set_matplotlib_formats, HTML\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "db = '#283db5' # Darkblue default\n",
    "ddb = '#0c112e'\n",
    "g = '#767676'\n",
    "cs = ['#43D789', '#801607', '#8DB8ED', '#94B0B6', '#e42c12', '#005CA8', '#127340', '#111851'] # Line colors\n",
    "cmap = matplotlib.colors.ListedColormap(['#e4e4e4', 'b', 'g']) # Color for False and True\n",
    "#cmap = 'Blues'\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10, 5)})\n",
    "sns.set_style('ticks', rc={ 'figure.facecolor': 'none', 'axes.facecolor':'none'})\n",
    "sns.set_context('notebook', rc={'lines.linewidth':1.5})\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dict = np.load('/Users/Daphne/Data/main_dict.npy', allow_pickle='TRUE').item()\n",
    "\n",
    "PCs_surr = np.load('surr_across_neurons.npy') # Load PC surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCs_surr = PCs_surr[:50, :, :] # take a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Parameters '''\n",
    "OTHER_ARRAY_D = 50 # Distance value to indicate other array\n",
    "\n",
    "TYPE_ANALYSIS = 'pooled' # alternative: 'm1', 'pmd' #TODO\n",
    "\n",
    "SESSIONS = ['Chewie_CO_VR_2016-09-09', 'Chewie_CO_VR_2016-09-12', 'Chewie_CO_VR_2016-09-14', 'Chewie_CO_VR_2016-10-06', \n",
    "            'Chewie_CO_FF_2016-09-15', 'Chewie_CO_FF_2016-09-21', 'Chewie_CO_FF_2016-10-05', 'Chewie_CO_FF_2016-10-07',\n",
    "            'Mihili_CO_VR_2014-03-04', 'Mihili_CO_VR_2014-03-06', 'Mihili_CO_FF_2014-02-03', 'Mihili_CO_FF_2014-02-17', \n",
    "            'Mihili_CO_FF_2014-02-18', 'Mihili_CO_FF_2014-03-07', 'Mihili_CO_VR_2014-03-03']\n",
    "\n",
    "THRESHOLDS_VARE = np.round(np.arange(0.2, 0.95, 0.025), 3)\n",
    "INTERVALS = [(0, 2), (0, 4)] # Fixed within intervals\n",
    "\n",
    "''' Load unit guides '''\n",
    "M1_UG = np.load('/Users/Daphne/Data/M1_UG.npy')\n",
    "PMD_UG = np.load('/Users/Daphne/Data/PMD_UG.npy')\n",
    "\n",
    "''' Experimental sessions and electrode maps '''\n",
    "m1_emap  = localize_elecs(read_cmp(file_path='/Users/Daphne/Data/Chewie Left M1 SN 6250-001474.cmp'),  elecs=range(1,97))\n",
    "pmd_emap = localize_elecs(read_cmp(file_path='/Users/Daphne/Data/Chewie Left PMd SN 6251-001469.cmp'), elecs=range(1,97))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Initialize surrogate dictionary '''\n",
    "surr_dict = {}\n",
    "for s in range(PCs_surr.shape[0]): surr_dict[f'{s}'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Add PCs to each surrogate '''\n",
    "for i, s in enumerate(surr_dict.keys()):\n",
    "    surr_dict[s]['pcs'] = PCs_surr[i, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Prepare dictionaries to store each step for level of var exp '''\n",
    "for s in surr_dict.keys():\n",
    "    surr_dict[s]['vare'] = {}\n",
    "    for th in THRESHOLDS_VARE:\n",
    "        surr_dict[s]['vare'][f'{th}'] = { 'distances_df': {} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define components range from original data (session = 2016-09-09)\n",
    "components_range = [np.argmax(main_dict['2016-09-09']['model'].explained_variance_ratio_.cumsum() > THRESHOLDS_VARE[i]) for i in range(len(THRESHOLDS_VARE))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [30:28<00:00, 36.57s/it]\n"
     ]
    }
   ],
   "source": [
    "for s in pbar(surr_dict.keys()):\n",
    "    \n",
    "    for i, r in enumerate(components_range):\n",
    "\n",
    "        if r == 0: r += 2 # Can't compute correlation between two values\n",
    "        elif r == 1: r += 1 \n",
    "            \n",
    "        L_surr = surr_dict[s]['pcs'][:, :r] # Get the first r PCs\n",
    "\n",
    "        # Get correlations and physical distances\n",
    "        C, PD, A, _ = compute_stat_and_phys_distances(L_surr, M1_UG, PMD_UG, m1_emap, pmd_emap)\n",
    "        \n",
    "        # Convert to dataframe\n",
    "        df = pd.DataFrame(data={'correlation': C, 'distance': PD, 'on array': A})\n",
    "        df['category'] = df['distance'].apply(lambda d: 'same electrode' if d == 0 else ('same array' if d < OTHER_ARRAY_D else ('other array')))\n",
    "        \n",
    "        # Store dataframe in surrogate dictionary\n",
    "        surr_dict[s]['vare'][f'{THRESHOLDS_VARE[i]}']['distances_df'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:47<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Perform LS regressions on each surrogate '''\n",
    "\n",
    "for s in pbar(surr_dict.keys()):\n",
    "    \n",
    "    for v in surr_dict[s]['vare'].keys(): \n",
    "        \n",
    "        # Empirical and surrogate data\n",
    "        variants = {\n",
    "          'Surr' : surr_dict[s]['vare'][f'{v}']['distances_df'],\n",
    "        }\n",
    "        # Dummy functions\n",
    "        int_dum = lambda df, lb, ub: df['distance'].apply(lambda x: 1 if lb < x <= ub else 0)\n",
    "        on_arr = lambda df, arr: df['on array'].apply(lambda x: 1 if x == arr else 0)\n",
    "        same_ele = lambda df: df['distance'].apply(lambda x: 1 if x == 0 else 0)\n",
    "        same_arr = lambda df: df['distance'].apply(lambda x: 1 if 0 < x < OTHER_ARRAY_D else 0)\n",
    "\n",
    "        # Analyses methods\n",
    "        analyses = {\n",
    "          'single_cat' : {\n",
    "            'fixed cols' : {\n",
    "              'OA Constant' : lambda df: [1] * len(df),\n",
    "              'SE (d = 0)' : same_ele,\n",
    "              'SA (d exists)' : same_arr,\n",
    "            },\n",
    "            'variable cols' : {}\n",
    "          }}\n",
    "        \n",
    "        for study, df in variants.items():\n",
    "            \n",
    "            for analysis, cols_dict in analyses.items():\n",
    "                df_X = pd.DataFrame()\n",
    "                for col_name, col_func in cols_dict['fixed cols'].items():\n",
    "                    df_X[col_name] = col_func(df)\n",
    "                for (lb, ub) in INTERVALS:\n",
    "                    for col_name, col_func in cols_dict['variable cols'].items():\n",
    "                        df_X[col_name + f'({lb:.1f}, {ub:.1f}]'] = col_func(df, lb, ub)\n",
    "                df_X = df_X.reindex(sorted(df_X.columns), axis=1)\n",
    "                res = sm.OLS(df.correlation, df_X, hasconst=True).fit()\n",
    "                title = f'{study}_{analysis}'\n",
    "                \n",
    "                surr_dict[s]['vare'][f'{v}'][title] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract betas for all three groups and save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract betas and pvalues for single cat \n",
    "\n",
    "beta0_surr = []\n",
    "for s in surr_dict.keys():\n",
    "    beta0_surr.append([surr_dict[s]['vare'][v]['Surr_single_cat'].params[0] for v in surr_dict[s]['vare'].keys()])\n",
    "beta0_surr = np.array(beta0_surr)\n",
    "\n",
    "beta1_surr = []\n",
    "for s in surr_dict.keys():\n",
    "    beta1_surr.append([surr_dict[s]['vare'][v]['Surr_single_cat'].params[1] for v in surr_dict[s]['vare'].keys()])\n",
    "beta1_surr = np.array(beta1_surr)\n",
    "\n",
    "beta2_surr = []\n",
    "for s in surr_dict.keys():\n",
    "    beta2_surr.append([surr_dict[s]['vare'][v]['Surr_single_cat'].params[2] for v in surr_dict[s]['vare'].keys()])\n",
    "beta2_surr = np.array(beta2_surr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 30)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(beta0_surr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save them\n",
    "beta0_surr = np.save('beta0_surr.npy', beta0_surr)\n",
    "beta1_surr = np.save('beta1_surr.npy', beta1_surr)\n",
    "beta2_surr = np.save('beta2_surr.npy', beta2_surr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract p, t values and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals_surr = []\n",
    "tvals_surr = []\n",
    "\n",
    "for s in surr_dict.keys():\n",
    "    \n",
    "    # SURROGATES\n",
    "    pvals_surr.append([surr_dict[s]['vare'][v]['Surr_single_cat'].pvalues.values for v in surr_dict[s]['vare'].keys()])\n",
    "    tvals_surr.append([surr_dict[s]['vare'][v]['Surr_single_cat'].tvalues.values for v in surr_dict[s]['vare'].keys()])\n",
    "    \n",
    "pvals_surr = np.array(pvals_surr) # (should be 50 x 30)\n",
    "tvals_surr = np.array(tvals_surr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save them\n",
    "np.save('pvals_surr', pvals_surr)\n",
    "np.save('tvals_surr', tvals_surr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform rank sum test on surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_twoSided_SE_SR = []\n",
    "sessions_twoSided_SE_OR = []\n",
    "sessions_twoSided_SR_OR = []\n",
    "\n",
    "sessions_lt_SE_SR = []\n",
    "sessions_lt_SE_OR = []\n",
    "sessions_lt_SR_OR = []\n",
    "\n",
    "sessions_gt_SE_SR = []\n",
    "sessions_gt_SE_OR = []\n",
    "sessions_gt_SR_OR = []\n",
    "\n",
    "for s in surr_dict.keys(): # for each session\n",
    "        \n",
    "    for v in surr_dict[s]['vare'].keys(): # for each threshold of variance explained\n",
    "        \n",
    "        df = surr_dict[s]['vare'][v]['distances_df'] # get df for that level of exp var\n",
    "        \n",
    "        # Get 3 distributions\n",
    "        corrs_SE = df.loc[df['category'] == 'same electrode']['correlation'].values\n",
    "        corrs_SR = df.loc[df['category'] == 'same array']['correlation'].values\n",
    "        corrs_OR = df.loc[df['category'] == 'other array']['correlation'].values\n",
    "        \n",
    "        # get lists of tuples (30 x 15) = (test statistic, pval)\n",
    "        sessions_twoSided_SE_SR.append(scipy.stats.ranksums(corrs_SE, corrs_SR, alternative='two-sided') * 1)\n",
    "        sessions_twoSided_SE_OR.append(scipy.stats.ranksums(corrs_SE, corrs_OR, alternative='two-sided') * 1)\n",
    "        sessions_twoSided_SR_OR.append(scipy.stats.ranksums(corrs_SR, corrs_OR, alternative='two-sided') * 1)\n",
    "        \n",
    "        # LESS THAN\n",
    "        sessions_lt_SE_SR.append(scipy.stats.ranksums(corrs_SE, corrs_SR, alternative='less') * 1)\n",
    "        sessions_lt_SE_OR.append(scipy.stats.ranksums(corrs_SE, corrs_OR, alternative='less') * 1)\n",
    "        sessions_lt_SR_OR.append(scipy.stats.ranksums(corrs_SR, corrs_OR, alternative='less') * 1)\n",
    "        \n",
    "        # LESS THAN\n",
    "        sessions_gt_SE_SR.append(scipy.stats.ranksums(corrs_SE, corrs_SR, alternative='greater') * 1)\n",
    "        sessions_gt_SE_OR.append(scipy.stats.ranksums(corrs_SE, corrs_OR, alternative='greater') * 1)\n",
    "        sessions_gt_SR_OR.append(scipy.stats.ranksums(corrs_SR, corrs_OR, alternative='greater') * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('surr_gt_SE_SR', sessions_gt_SE_SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('surr_gt_SE_OR', sessions_gt_SE_OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('surr_gt_SR_OR', sessions_gt_SR_OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Generating surrogates with one session\n",
    "# W = main_dict['2016-09-09']['pcs']\n",
    "# N_surrogates = 100\n",
    "# surr_data = []\n",
    "\n",
    "# for i in range(N_surrogates):\n",
    "    \n",
    "#     surr_data.append(np.random.permutation(W))\n",
    "#np.save('surr_across_neurons', Surr_across_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rand_row_idx = random.sample(range(X_concat.shape[0]), X_concat.shape[0])\n",
    "# rand_row_idx = random.sample(range(A.shape[0]), A.shape[0])\n",
    "\n",
    "# print(rand_row_idx)\n",
    "\n",
    "# # Randomize the rows of the data matrix\n",
    "# X_rand_neurons = A[rand_row_idx, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
